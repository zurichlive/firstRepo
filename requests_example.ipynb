{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function = 'count?'\n",
    "function = 'query?'\n",
    "basis_url = 'https://earthquake.usgs.gov/fdsnws/event/1/'\n",
    "fmt = '&format=geojson'\n",
    "\n",
    "date_start = datetime.date(2018, 9, 1)\n",
    "date_end = datetime.date(2018, 9, 30)\n",
    "date_search= 'starttime='+str(date_start)+'&endtime='+str(date_end)\n",
    "# date_search= date_search +'&minmagnitude=6'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop for several months\n",
    "#for x in range(0,3):\n",
    "#    date_start = datetime.date(date_start.year, date_start.month+x, date_start.day)\n",
    "#    date_end = datetime.date(date_end.year, date_end.month+x, date_end.day)\n",
    "#    date_search= 'starttime='+str(date_start)+'&endtime='+str(date_end)\n",
    "#    date_search= date_search +'&minmagnitude=6'\n",
    "#    \n",
    "#    r = requests.get(basis_url + function + date_search)\n",
    "#    r.status_code\n",
    "#    if r.status_code == 200:\n",
    "#        print(str(date_start) + ' - ' + str(date_end) + ': ' + r.text)\n",
    "        #print(r.json()) # dictionary\n",
    "\n",
    "#print(date_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = requests.get('https://www.admin.ch/gov/de/start/dokumentation/veranstaltungen.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://earthquake.usgs.gov/fdsnws/event/1/query?starttime=2018-09-01&endtime=2018-09-30&format=geojson\n",
      "dict_keys(['type', 'metadata', 'features', 'bbox'])\n"
     ]
    }
   ],
   "source": [
    "#r = requests.get('https://earthquake.usgs.gov/fdsnws/event/1/count?starttime=2018-09-01&endtime=2018-09-30')\n",
    "r = requests.get(basis_url + function + date_search + fmt)\n",
    "r.status_code\n",
    "print(r.url)\n",
    "json = r.json()\n",
    "#json.keys()\n",
    "print(json.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(r.text)\n",
    "json = r.json()\n",
    "json.keys()\n",
    "json.get('metadata') # or json['metadata']\n",
    "\n",
    "json['features'][0]['properties']['place']\n",
    "\n",
    "quake_list = []\n",
    "\n",
    "#for quake in json.get('features')[:10]:\n",
    "#for quake in json['features'][:10]:\n",
    "#\n",
    "# iterate through all quakes\n",
    "for quake in json['features']:\n",
    "    # read properties\n",
    "    props = quake['properties']\n",
    "    # read magnitude\n",
    "    mag = props['mag']\n",
    "    # read place\n",
    "    place = props['place']\n",
    "    # print(str(place) + ': ' + str(mag)) \n",
    "    # \n",
    "    # create dictionary and add to list\n",
    "    quake_dict = {'place':place, 'magnitude':mag}\n",
    "    quake_list.append(quake_dict)\n",
    "    \n",
    "#print(quake_list)\n",
    "\n",
    "# store data\n",
    "data = pd.DataFrame(quake_list)\n",
    "data.to_csv(\"magnitude.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6b/dc/3a88b7bf8437f3f052fc90de72f28c06248142821a7f108e10ff3be5eb59/pandas-0.23.4-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (14.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 14.4MB 325kB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2011k in /Users/florian/.virtualenvs/erstesVE/lib/python3.7/site-packages (from pandas) (2018.5)\n",
      "Collecting numpy>=1.9.0 (from pandas)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/64/f47c172c2d2ee8907b5918ff7af7e52207f6bf4a57983e4474fcda728112/numpy-1.15.2-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (24.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 24.5MB 746kB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.0 in /Users/florian/.virtualenvs/erstesVE/lib/python3.7/site-packages (from pandas) (2.7.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/florian/.virtualenvs/erstesVE/lib/python3.7/site-packages (from python-dateutil>=2.5.0->pandas) (1.11.0)\n",
      "Installing collected packages: numpy, pandas\n",
      "Successfully installed numpy-1.15.2 pandas-0.23.4\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(r)\n",
    "print(r.status_code)\n",
    "if r.status_code == 200:\n",
    "    print(r.text)\n",
    "    print(r.json()) # dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for x in (0,3):\n",
    "#    date_search = 'starttime='+str(date = date_start.month+x)+'&endtime='+str(date_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5: 492\n",
      "6: 43\n",
      "7: 6\n"
     ]
    }
   ],
   "source": [
    "list1 = ['2018-07-01', '2018-08-01', '2018-09-01']\n",
    "list2 = ['2018-07-31', '2018-08-31', '2018-09-30']\n",
    "magnitudes = [5,6,7]\n",
    "magnitudes_results = {}\n",
    "function = 'count?'\n",
    "\n",
    "for date,date2 in zip(list1,list2):\n",
    "    # iterate through lists \n",
    "    for magnitude in magnitudes:\n",
    "        quakes = requests.get(basis_url + function + 'starttime=' + date + '&endtime=' + date2 + '&minmagnitude=' + str(magnitude))\n",
    "        #print(date, date2, magnitude, quakes.text)\n",
    "        if magnitude in magnitudes_results.keys():  \n",
    "            magnitudes_results.update({magnitude: int(magnitudes_results.get(magnitude))+int(quakes.text)})\n",
    "        else:\n",
    "            magnitudes_results.update({magnitude: quakes.text})\n",
    "\n",
    "for magnitude in magnitudes:\n",
    "    print(str(magnitude) + ': ' + str(magnitudes_results.get(magnitude)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
